# CHAPTER 17. Testing for Reliability

'시스템에 대한 정량화된 신뢰도'는 SRE 엔지니어의 핵심 책임 중 하나

신뢰도는 과거의 신뢰성 정도와 미래의 신뢰성 정도를 모두 포함하여 측정

**과거의 신뢰성**: 
: 모니터링 기록 시스템이 제공하는 분석 데이터를 통해 확보

**미래의 신뢰성**:
: 예측 데이터를 정량화하여 확보

테스트는 변경 사항이 있을 때, 
특정 부분에서 동일한 결과를 기대할 수 있다는 것을 보여주기 위한 메커니즘,

따라서 아래 조건 중 하나는 만족해야 함: 

- 테스트로 인한 소프트웨어나 서버의 변경이 없어야 하며, 이를 통해 향후 시스템 동작이 과거와 유사하게 유지될 수 있어야 함.
- 시스템의 모든 변경 사항에 대해 불확실성을 염두에 두고, 변경된 부분을 명확히 설명할 수 있어야 함.

실제로 수행해야 하는 테스트의 양은 시스템의 신뢰성 요구 수준에 따라 다름

테스트에 의해 검증이 가능한 기반 코드가 늘어날수록 불확실성과 변경으로 인해 발생할 수 있는 잠재적인 신뢰성의 하락을 완화

<pre> Relationships between Testing and Mean Time to Repair 
수정에 소요된 시간(Mean Time to Repair, MTTR): 버그를 수정하기까지 소요된 시간

테스트 시스템을 활용하면 MTTR가 0(Zero)인 버그 확인 가능.
MTTR이 제로라는 것은 시스템 수준의 테스트가 서브시스템에 적용되어,
그 테스트가 모니터링 시스템이 관측할 수 있는 것과 정확히 동일한 문제를 발견해냈다는 것을 의미.
즉, 변경된 코드의 배포 전에 버그를 발견해서 실제 프로덕션 환경에 버그가 있는 코드가 배포될 가능성이 없어짐

제로 MTTR을 통해 더 많은 버그를 찾아낼수록 사용자가 경험하는 장애 발생 시간의 간격(Mean Time Between Failure, MTBF) 이 높아지게 됨
</pre>

## Types of Software Testing

- **Traditional Tests**
  - 전통적인 테스트: 개발하는 동안 소프트웨어가 올바른 동작을 수행하는지 여부를 평가
- **Production Tests**
  - 프로덕션 테스트: 실제 동작하는 웹 서비스에 대해 배포된 소프트웨어 시스템이 올바르게 동작 중인지를 판단하는 테스트

<br>

### Traditional Tests

#### Unit tests

클래스나 함수를 테스트하여 이 단위들로 구성된 전체 소프트웨어 시스템의 동작을 독립적으로 테스트하는 방법

단위 테스트는 함수나 모듈이 시스템이 요구하는 정확한 동작을 수행하는지에 대한 명세(specification)의 역할

테스트 주도 개발(Test Driven Development, TDD) 방법론과 함께 사용

#### Integration tests
대거(Dagger)와 같은 의존성 주입(dependency injection) 도구는 컴포넌트가 가진 복잡한 의존 객체들의 모조(mock) 객체를 생성해주는 강력한 도구

<pre><b><a href="https://dagger.dev/">Dagger</a></b>
Dagger is a fully static, compile-time dependency injection framework for Java, Kotlin, and Android. It is an adaptation of an earlier version created by Square and now maintained by Google.
</pre>

의존성 주입을 이용하는 가장 보편적인 방법 중 하나는 상태를 저장하는 데이터베이스를 가벼운 Mock 객체로 교체하여 특정 동작을 정확하게 테스트하는 것

#### System tests
: 종단 간 기능 테스트

##### Smoke tests

: 스모크 테스트 = 세니티 테스트 (sanity test)

가장 간단한 형태의 시스템 테스트

엔지니어가 시스템의 간단하지만 중요한 동작을 테스트하는 방법

더 많은 범위의 짧은 경로를 테스트하고 비용이 더 필요

##### Performance tests
: 성능 테스트

개발 과정에서 의존성을 가진 서비스의 응답 시간이나 시스템이 필요로 하는 자원에 대한 요구사항이 완전히 바뀔 수 있으므로 갑자기 시스템의 성능이 느려지는 일이 없다는 것 역시(사용자가 먼저 알아차리기 전에) 확실히 해야 함

어느 정도 시간이 지나면서 시스템의 성능이 줄어들거나 더 많은 자원을 사용하는지를 확인

##### Regression tests
: 회귀 테스트

이미 알려진 버그들을 통해 시스템의 실패나 잘못된 결과가 나타나는 것을 유추하는 테스트

기존에 시스템 테스트나 통합 테스트 과정에서 발생했던 버그들을 테스트 형태로 작성해두면 엔지니어들이 코드를 리팩토링하는 과정에서 이미 시간과 노력을 들여 발견하고 수정한 버그들을 실수로 다시 만들어내는 일을 방지

**📝 버그 수정에는 시간과 분석에 대한 자원이라는 비용이 소모됨**

- 모든 의존 서비스들(혹은 이들의 Mock 서비스들)과 함께 완전한 형태의 서비스를 이용하여 관련된 테스트를 수행하는 것은 훨씬 더 많은 시간(몇 분에서 몇 시간까지 소요)과 전용의 컴퓨팅 자원이 필요

### Production Tests

: 프로덕션 테스트 = 블랙박스 테스트

실제 프로덕션 시스템을 대상으로 이루어지는 테스트

#### Configuration test

구글에서는 웹 서비스의 설정은 파일에 기록되어 버전 제어 시스템에 저장

각 설정 파일마다 별도의 설정 테스트(configuration test)가 구현되어있음

실제 프로덕션 환경에서 동작하는 특정 바이너리가 실제로 어떻게 설정되어있는지를 확인하고 해당 설정 파일과 일치하지 않는 부분을 찾아보는 것

설정 테스트는 버전 제어 시스템에 체크인된 특정 버전의 설정 파일을 이용하여 빌드 및 실행

목표한 버전과 실제로 테스트를 통과한 버전을 비교함으로써 실제 프로덕션 환경이 그동안 진행된 엔지니어링 작업에 비해 얼마나 뒤처져있는지를 판단

<br>

**설정 테스트가 유용한 설정 파일 예시**:

- 파일 콘텐츠를 사용하며, 해당 콘텐츠를 쉽게 조회할 수 있는 실시간 쿼리를 지원
  - 간단하게 쿼리를 실행하여 결과를 실제 파일과 비교

**설정 테스트가 복잡해지는 설정 파일 예시**:

- 바이너리에 내장된 기본 값을 사용하는 설정
  - 테스트의 결과는 별개의 버전이 됨
- 전처리 시 지정되는 설정
  - 배시셸의 명령줄 플래그
- 공유 런타임 중, 특정 문맥에 의존적인 동작을 명시적으로 제어하는 설정
  - 테스트가 런타임 릴리즈 일정에 의존성을 가짐

#### Stress test

안전한 운영을 위한 시스템의 한계를 알아내기 위해 사용

**검증 예시:**

- 데이터베이스 용량이 어느 정도에 도달할 때 쓰기 작업에 실패하는가?
- 애플리케이션 서버는 초당 몇 개의 쿼리까지 응답할 수 있는가?


#### Canary test

프로덕션 환경을 대상으로 하는 테스트에는 잘 적용하지 않음

서버의 일부만을 새로운 버전의 바이너리나 설정 파일로 업그레이드한 후 일정 기간 동안 지켜보는 형태로 진행

- 문제가 발생하지 않으면 → 나머지 서버들도 점진적으로 업그레이드
- 문제가 발생하면 → 문제가 발생한 해당 서버만 롤백

업그레이드된 서버들을 지켜보는 기간을 '**baking the binary**'라고 표현함

- **설정 테스트** / **스트레스 테스트**: 지정된 소프트웨어에 대한 특정 상태의 존재 여부를 파악하기 위한 방법인 반면, 
- **카나리 테스트**: 그보다 더 즉흥적으로 이루어지는 방법임

<pre><b>예시</b>

사용자 트래픽에 상대적으로 영향을 미친 결함이 업그레이드를 거쳐 배포된 후 갑자기 기하급수적으로 증가함.

<b>오류의 누적 횟수 CU=PK</b>

- R: the rate of those reports. 리포트의 비율
- U: the order of the fault (defined later). 오류 순서
- K: the period over which the traffic grows by a factor of e, or 172%. 특정 요인 e에 의해 트래픽이 증가된 기간 또는 172%를 의미

사용자의 피해를 줄이려면 예상하지 못한 문제가 발생한 배포를 신속하게 취소하고 이전 버전의 설정으로 롤백해야 함

잠시 동안 자동화를 이용해 변화의 추이와 반응을 살펴봄.
그 동안 몇 개의 추가 보고가 생성됨.
일단 문제가 해결되면 이 보고들을 통해 누적 횟수 C와 비율 R을 예측할 수 있음.

이를 X로 나누면 발생했던 문제의 순서인 U를 예측할 수 있음.

- `U=1`: 사용자의 요청이 문제가 발생한 코드로 인해 처리되지 않음
- `U=2`: 사용자의 요청이 랜덤하게 데이터를 손실시켜 다음 사용자의 요청에서 손실된 데이터가 나타남
- `U=3`: 랜덤하게 손실된 데이터가 이전 요청에서 유효한 식별자로 사용됨

대부분의 버그는 첫 번째 해당 <- 사용자 트래픽의 양에 따라 선형적으로 증가

높은 순서의 버그와 낮은 순서의 버그의 우선순위를 고려한다면, 지수적인 롤아웃 전략을 사용할 때, 사용자 트래픽과의 연관 관계를 생각하지 않아도 됨.
동일한 K 간격을 사용하는 한, 오류 원인을 확정할 수 없더라도, U에 대한 예측값은 여전히 유효하기 때문.

약간의 중복 값을 허용하면서 순차적으로 많은 방법을 사용하면 X의 값을 작게 유지할 수 있음.
U의 값을 조기 예측하면서, 사용자가 장애를 경험하는 전체 횟수인 C를 최소화할 수 있음.
</pre>


## Creating a Test and Build Environment

팀의 기반 코드가 여전히 프로토타입 단계이며, 이에 대한 전반적인 테스트는 아직 정의되지 않은 상태인 경우임. 이런 상황이라면 어느 부분부터 테스트를 시작해야 할까? 

최소한의 노력으로 최상의 효과를 낼 수 있는 테스트를 수행해야 함

- 코드의 우선순위를 결정할 수 있는가?
- 비즈니스 관점에서 중요한 기능이나 클래스를 특정할 수 있는가?
- 다른 팀들이 통합해서 사용하는 API들이 있는가? 

강력한 테스트 문화를 수립할 수 있는 방법 중 하나는 지금까지 보고된 모든 버그를 **테스트 케이스의 형태로 문서화**하는 것임

Bazel은 소프트웨어 프로젝트의존성 그래프를 생성해줌. 어떤 파일에 변경이 발생하면 Bazel은 그 파일에 의존하는 부분만 다시 빌드함

또한 이런 시스템들은 재생산 가능한 빌드를 제공함

<br>

## Testing at Scale

상대적으로 규모가 작은 단위 테스트의 경우 몇 가지 의존성을 가지고 있음
- 단일 소스 파일, 테스트 라이브러리, 런타임 라이브러리, 컴파일러, 테스트를 실행하는 로컬 하드웨어 등

견고한 테스트 환경이라면 이들 역시 테스트 환경의 각기 다른 부분들에 대해 기대하는 여러 가지 활용 사례(use case)를 확인하기 위한 자신만의 테스트 커버리지를 확보하고 있어야 함

실용적인 테스트 환경은 여러 버전과 병합(merge) 중에서 적절한 브랜치를 선택해 테스트를 수행할 수 있어야 함

(각 브랜치에 해당 기능을 테스트할 수 있도록 코드를 잘 분리해야 함)

<br>

### Testing Scalable Tools

**SRE가 사용하는 도구의 테스트**

**수행 작업:**
- 데이터베이스 성능 지표의 조회 및 배포
- 가용성 위험에 대한 계획 수립을 위한 사용량 예측
- 사용자가 접근할 수 없는 서비스 복제본의 데이터 리팩토링
- 서버상의 파일 변경

**특징:**
- 도구들의 부작용이 테스트를 수행한 메인스트림 API에 그대로 남음
- SRE가 개발한 도구들은 유효성 검사 및 릴리즈 장벽으로 인해 사용자 직접 접근하는 프로덕션 환경과는 격리된 환경에서 실행

**자동화 도구 테스트**

훨씬 세밀한 테스트가 필요함. 자동화 도구들은 다음과 같은 작업을 수행함

- 데이터베이스 인덱스 선택
- 데이터센터 간의 로드 밸런싱
- 신속한 리마스터링(remastering)을 위한 릴레이 로그 혼합

**특징:**
- 실제로 작업은 주로 견고하고, 예측 가능하며, 충분히 테스트된 API들을 대상으로 수행됨
- 수행되는 작업의 목적에 따라 작업 수행 도중 다른 API 클라이언트들에게서 알 수 없는 중단 현상이 발생할 수 있음

한 자동화 도구가 다른 자동화 도구가 실행되는 환경을 바꿔버릴 수 있다는 점 고려해야 함

### Testing Disaster

: 재해 테스트

많은 재해 복구 도구는 오프라인 상태에서도 동작할 수 있도록 세심한 주의를 기울여 만들어짐

- 깨끗하게 정지시킨 서비스 상태가 되도록 체크포인트(checkpoint) 계산
- 기존의 무결성 도구를 적재할 수 있도록, 체크포인트를 적재 가능한 상태로 만듦
- 재시작 절차를 수행하는 릴리즈 경계 도구들을 지원

온라인 복구 도구들은 본질적으로 메인스트림 API와는 별개로 동작함

최종적 일관성(eventual consistency)을 지향하는 본질적인 성향이 복구 과정에는 오히려 도움이 되지 않는 경우가 있음

### The Need for Speed

코드저장소의모든버전(패치)에대해정의된모든테스트들은성공혹은실패만을표시할뿐

### Pushing to Production
### Expect Testing Fail
### Integration
### Production Probes
## Conclusion


