# CHAPTER 06. Monitoring Distributed Systems

_분산 시스템 모니터링_

### 정의

#### ✔️ 모니터링

: 시스템의 정량적 실시간 데이터를 모으고 처리하고 집계해서 보여주는 것

(시스템 데이터: 쿼리의 수와 종류, 에러의 수와 종류, 처리 시간 및 서버의 활동 시간 등)

#### ✔️ 화이트박스(white-box) 모니터링
: 로그나 Java Virtual Machine (JVM)의 프로파일링 인터페이스(profiling interface) 같은 인터페이스 혹은 내부의 통계 지표를 제공하는 HTTP 핸들러 등을 이용해서 얻은 시스템의 내부 지표들을 토대로 하는 모니터링

#### ✔️ 블랙박스(black-box) 모니터링
: 사용자가 보게 되는 확인 가능한 동작들을 외부에서 테스트하는 과정

#### ✔️ 대시보드(dashboard)
: 서비스의 핵심 지표에 대한 요약된 뷰를 보여주는 (주로 웹 기반) 애플리케이션

대시보드는 필터나 선택 옵션 등을 제공하기도 하지만, 가장 중요한 지표들을 사용자에게 보여주도록 만들어져 있음. 또한, 쌓여있는 티켓의 숫자나 높은 우선순위를 갖는 버그의 목록, 현재 비상 대기 중인 엔지니어와 담당하는 분야 혹은 최근에 배포된 코드 등 팀과 관련된 정보를 보여주기도 함

#### ✔️ 알림(alert)
: 사람이 읽을 수 있도록 작성된 통지(notification)를 말하며, 주로 버그나 티켓 큐, 메일, 혹은 호출기 등으로 보내짐.

이런 알림들은 각각 티켓, 메일 알림 및 호출 등으로 분류됨

#### ✔️ 근본 원인
: 소프트웨어 시스템의 결함이나 사람의 실수는 일단 고쳐지면 그 일이 다시는 발생하지 않을 것이라는 확신을 심어줌

이런 사고는 여러 원인에 의해 발생할 수 있음

예를 들어 프로세스의 자동화가 충분하지 못해서 발생할 수도 있고, 조작된 정보에 의해 소프트웨어가 충돌해서 발생할 수도 있고, 설정을 생성하는 스크립트의 테스트가 제대로 수행되지 않아 발생할 수도 있음. 모두 수정되어야 함

#### ✔️ 노드와 머신
: 물리적인 서버, 가상 머신 혹은 컨테이너(container)에서 동작하는 커널의 단일 인스턴스를 의미하며 동의어로 사용됨

한 머신이 모니터링할 여러 개의 서비스를 운영하고 있을 수도 있는데, 크게 두 가지로 구분할 수 있음

#### ✔️ 서로 관련된 서비스: 캐시 서버와 웹 서버
서로 관련이 없지만 하드웨어만 공유하는 서비스: 코드 저장소와 Puppet이나 Chef 같은 설정 시스템의 마스터 노드

#### ✔️ 푸시(push)
: 서비스가 실행하는 소프트웨어나 관련된 설정에 대한 모든 변경사항

<br>

### 왜 모니터링해야 하는가?

언제 문제가 발생했는지 또는 어떤 문제가 발생하려 하는지를 알 수 있음

효과적인 알림 시스템은 정확한 신호와 낮은 오보 비율을 갖춰야 함

- **장기적인 트렌드 분석**
- **시간순 혹은 실험 그룹에 대한 비교**
  - 어느 것이 쿼리를 더 빨리 실행하는가?
  - 노드를 추가했을 때 memcache의 활용률(hit rate)은 어느 정도나 좋아지는가?
  - 지난주 대비 사이트가 느려졌는가?
- **알림**
- **대시보드**: 네 가지 골든 신호를 포함
- **임시적인 회고 분석의 수행** (ex. 디버깅 등)

<br>

### 모니터링에 대한 적절한 기대치 설정

- 최대한 간결하면서도 팀 모두가 이해할 수 있도록 유지하는 것
  - (특히 프로덕션 환경에서 문제가 발생해서 사람을 호출하고, 기본적인 점검과 심도 깊은 디버깅을 실행하기까지의 경로를)
- 잘못된 알림(noise) 비율을 낮게 유지하고 올바른 알림의 비율을 높게 유지하기 위해서는 호출을 담당하는 모니터링 시스템은 반드시 간결하면서도 안정적이어야 함 
- 사람이 확인할 알림을 발송하기 위한 규칙들은 이해하기 쉽고 문제를 명확하게 표현할 수 있어야 함

<br>

### 증상과 원인
| 	증상	                     | 	원인	                   |
|--------------------------|------------------------|
| **"어떤 장애가 발생했는가?"** - 무엇 | **"왜 장애가 발생했는가?"** - 왜 |
|   HTTP 500이나 404 오류        |  데이터베이스 서버가 연결 요청을 거부함    |
|   응답 속도가 느려짐        |  비효율적인 로직에 의한 CPU 과부하가 발생함 또는 랙 아래의 이더넷 케이블 파손으로 인한 패킷이 부분적으로 유실됨    |
|   남극의 사용자가 고양이가 등장하는 애니메이션 GIF 파일을 수신하지 못함        |  CDN 서비스가 과학자와 고양잇과 동물을 싫어해서 일부 IP를 블랙리스트에 등록했음    |
|   개인정보가 유출	        |  새로 배포한 소프트웨어가 ACL을 잘못 설정해서 모든 요청에 응답함    |

'무엇'과 '왜'는 최대 비율의 정상적 알림과 최소 비율의 오보를 목적으로 하는 모니터링 시스템을 작성할 때 고려해야 하는 가장 중요한 간극 중 하나

<br>

### 블랙박스와 화이트박스

- 블랙박스 모니터링: 서버 상에 나타나는 증상을 기본으로 하며 현재 문제가 (발생할 것으로 예상되는 것이 아니라) 발생하는 상황을 모니터링하는 것
  - 즉, 시스템이 지금 현재 올바로 동작하지 않고 있는 상황을 알기 위한 것
- 화이트박스 모니터링: 로그나 HTTP 종단점(endpoint)과 같은 시스템의 내부 동작들을 규범에 따라 살펴보는 기법들을 토대로 함
  - 문제가 발생하려는 재시도에 의해 가려진 실패 작업 등을 포착할 수 있음
  - 원격으로 디버깅을 수행할 때는 화이트박스 모니터링이 필수적

<br>

### 네 가지 결정적인 지표
1. **지연 응답**: 요청이 서비스에 의해 처리되기까지의 시간
   - 빠르게 리턴된 에러보다는 느리게 리턴된 에러가 더 중요
2. **트래픽**: 시스템에 얼마나 많은 요청이 들어오는지를 측정
   - 초당 HTTP 요청의 개수로 측정
3. **에러**: 실패한 요청의 비율
   - 명시적인 실패(ex. HTTP 500)와 묵시적인 실패(ex. HTTP 200이지만 잘못된 콘텐츠가 제공된 경우), 혹은 정책과 관련된 실패(ex. 모든 응답을 1초 내에 제공하기로 했다면 1초 이상 소요된 응답은 에러)를 모두 고려해야 함
   - 로드밸런서를 통해 모든 HTTP 500 에러를 검출하면 실패한 요청들을 모두 완벽하게 잡아낼 수 있음
4. **서비스 포화 상태**
  - 서비스가 얼마나 '포화 상태'로 동작하는지를 의미
  - 시스템의 일부를 측정하며 가장 병목이 발생하는 리소스를 집중해서 측정해야 함
  - CPU 사용량이나 이미 상한선이 분명한 네트워크 대역폭 같은 간접적인 신호들을 사용할 수밖에 없음


<br>

### 마지막 요청(혹은 실행과 성능)에 대한 고려
평균 응답 시간이 느려지는 것과 마지막 요청(tail of requests)이 아주 느려지는 것을 구분하는 간단한 방법은 실제 지연 응답이 아니라 전체 요청의 수와 전체 지연 응답을 수집하는 것

분포의 경계를 대략적으로 산정해서 분포해보면(이 예시의 경우에는 대충 세 가지 범위만을 추출해서 분포해보면) 요청이 어떻게 분포되는지를 시각적으로 확인할 수 있다.



<br>

### 적당한 측정 방법 선택하기

여러 서버에 걸쳐 데이터를 수집하고 시계열로 집계하는 외부 시스템을 구성하면 비용을 줄일 수 있음

1. 매초마다 현재 CPU의 사용량을 기록
2. 5% 단위로 버킷(bucket)을 구성하고 매초당 CPU 사용량을 측정하여 적절한 버킷의 값을 증가시킴
3. 분 단위로 이 값들을 집계


<br>

### 더욱 단순하게가 아니라 최대한 단순하게

- 가장 빈번하게 발생하는 사건/사고를 탐지하기 위한 규칙은 최대한 간결하고 예측 가능하며 확실해야 함
- 수정 빈도가 높지 않은(어떤 SRE 팀은 분기에 한 번 수정하기도 하는) 데이터의 수집, 집계 그리고 알림에 관련된 설정은 제거하는 것이 좋음
- 수집은 되지만 대시보드에 노출되지도 않고 알림에 사용되지도 않는 데이터는 역시 제거하는 것이 좋음

<br>

### 지금까지 살펴본 원리들을 결합하기

- 매번 호출기가 울릴 때마다 긴급한 상황임을 인지하고 그에 대응할 수 있어야 함.
  - 이러한 긴급 호출은 빈번한 호출로 인한 피로를 느끼지 않도록 하루에 단 몇 번 정도만 발생해야 함
- 모든 호출은 대응이 가능해야 함
- 호출에 대한 모든 대응은 이성적이어야 함.
  - 만일 호출이 자동화된 응답에 대해서만 가치가 있다면 이 호출은 전파되어서는 안됨
- 호출은 새로운 문제나 지금까지 보지 못한 사건에 대한 것이어야 함

**위 시스템의 복잡도에 관계없이 올바른 모니터링을 구성하는데 도움을 주는 질문들**

- 이 규칙은 해당 규칙이 존재하지 않는다면 알아챌 수 없는 긴급하고, 대처가 가능하며 즉각적으로 사용자가 인지할 수 있는 상태를 탐지할 수 있는가?
- 긴급하지 않은 알림이라면 무시할 수 있는 알림인가? 
  - 언제, 왜 이 알림을 무시할 수 있으며, 이런 알림을 받지 않으려면 어떻게 해야 할까?
- 이 알림은 분명히 사용자에게 좋지 않은 영향을 미치는 상황에 대한 알림인가?
- 가용 트래픽이 모두 소모되었거나 테스트 배포처럼 사용자에게 부정적인 영향을 미치지 않는 경우에는 알림이 발생하지 않았는가?
- 이 알림에 대해 대응이 가능한가? 
  - 이 알림은 긴급한 것인가 아니면 내일 아침까지 기다려도 되는 것인가?
  - 대응책은 안전하게 자동화가 가능한가?
  - 알림에 대한 대응은 장기적인 수정이 될 것인가 아니면 단기적인 우회책이 될 것인가?
- 다른 사람들이 이 이슈에 대한 호출을 받아서 적어도 하나 이상의 불필요한 호출이 발생했는가?

<br>

### 장기적 모니터링

누군가 문제의 근본적인 원인을 찾아 해결해야 함

만일 해결이 불가능하다면 알림에 대한 대응이 완전히 자동화되어야 함
